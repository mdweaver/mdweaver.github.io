---
title: "POLI 572B"
author: "Michael Weaver"
date: "January 25, 2021"
widgets: [bootstrap]
output: 
  revealjs::revealjs_presentation:
    theme: white
---

```{r setup, include = F}
require(knitr)
require(magrittr)
require(kableExtra)
options("kableExtra.html.bsTable" = T)
```

<style type="text/css">
  .reveal h2,h3,h4,h5,h6 {
    text-align: left;
  }
  .reveal p {
    text-align: left;
  }
  .reveal ul {
    display: block;
  }
  .reveal ol {
    display: block;
  }
  .table-hover > tbody > tr:hover { 
  background-color: #696969;
  color: #FFFFFF;
  }
</style>

# Potential Outcomes Model and Non-Compliance

## Plan for Today

### Non-compliance in experiments

- Example and the Problem
- Solutions
- CACE
- Practice

# Example

---

### Example:

Medical researchers have developed a new diagnostic test that can detect pre-cancerous growths. 

To find out whether this test actually results in medical interventions that reduce mortality, they conduct a randomized experiment in which half the study group is, at random, invited to come take the screening.

---

### Example:

>- Imagine you are **invited**: would you come take the screening?

>- Imagine you were **not invited** (but found out about the test): would you try to take the screening?

---


---

### Non-compliance

**Non-compliance** in experiments occurs when units that are randomly assigned to treatment or control do not take their assigned treatment condition.

- e.g. in a medical trial for a new drug, patients assigned to a control group seek out the treatment anyway
- in an experiment on contacting voters, people do not answer the phone or answer the door.
- wartime drafts assigned people to treatment by random numbers, but some people dodged the draft or were found exempt

---

### "Non-compliance"

#### more broadly:

experiments OR natural experiments in which there is random (as-if random) process of assigning exposure, but **not all units** follow this random process.

---

### Non-compliance

How do we find the effect of **treatment**...

- when some assigned to treatment **don't take it**
- when some assigned to no-treatment **do take it**

---

### Our example:

In 1963, researchers for the Health Insurance Plan of Greater New York (HIP) conducted the first randomized trial testing the effectiveness of mammography on reductions in breast cancer mortality.

60,000 women were randomly assigned to (T) be invited to be screened or (C) not invited.


---

### Mammography

Many who were invited chose not to be screened.

None who were not invited were screened.

- How could they find the effect of mammography on breast cancer death rates when large numbers of treatment group never were treated?

---


```{r, echo = F}
require(magrittr)
c_n = 10000
nt_n = 20000
w_nt = (nt_n/(c_n + nt_n))
w_c = (c_n/(c_n + nt_n))
c1 = 2
c0 = 2.5
nt = 1.5

c1_n = rbinom(c_n, 1, c1 / 1000) %>% sum
c0_n = rbinom(c_n, 1, c0 / 1000) %>% sum
nt1_n = rbinom(nt_n, 1, nt/1000) %>% sum
nt0_n = rbinom(nt_n, 1, nt/1000) %>% sum

while ((c1_n <= c0_n) & 
        (c1_n/10) <= ((nt1_n + nt0_n + c0_n)/50) & 
        (c1_n/10) <= ((nt0_n + c0_n)/30) & 
       (c1_n + nt1_n) >= (nt0_n + c0_n)
) {
  c1_n = rbinom(c_n, 1, c1 / 1000) %>% sum
  c0_n = rbinom(c_n, 1, c0 / 1000) %>% sum
  nt1_n = rbinom(nt_n, 1, nt/1000) %>% sum
  nt0_n = rbinom(nt_n, 1, nt/1000) %>% sum
              }

hip = data.frame(z = c("Control", "Treatment", "Treatment"),
                          d = c('No', 'No', 'Yes'),
                          N = c(30000, 20000, 10000),
                          bc_deaths = c(nt0_n + c0_n, nt1_n, c1_n),
                          bc_rate = c((nt0_n + c0_n)/30, nt1_n/20, c1_n/10) %>% round(2),
                          all_deaths = c((nt0_n + c0_n),
                                          (nt1_n + c1_n), NA),
                          all_rate = c((nt0_n + c0_n)/30, (nt1_n + c1_n)/30, NA) %>% round(2))

kable(hip, format = 'html',
      col.names = c("Assignment", "Screened", "$N$", "BC Deaths", "BCD per 1k", "BC Deaths (total)", "BCD per 1k (total)")) %>% 
  group_rows("Control Group", 1,1) %>% 
  group_rows("Treatment Group", 2,3)
  
```

---

### Mammography

What is the effect of **mammography**?

#### Option 1:

Compare all **treated** (screened) to all **untreated** (not screened in both T and C)

>- This comparison says: effect of mammography is to increase breast cancer mortality rate by `r round((c1_n/10) - ((c0_n + nt1_n + nt0_n)/50), 2)` per 1000!

---

### Mammography

What is the effect of **mammography**?

#### Option 2:

Compare all **treated** (screened) to the assigned-to-**control** group.

>- This comparison says: effect of mammography is to increase breast cancer mortality rate by `r round((c1_n/10) - ((c0_n + nt0_n)/30), 2)` per 1000!

---

### What has gone wrong here?

Do mammograms **increase** the risk of death from breast cancer?

DISCUSS

---

---

### Mammography

#### Option 3:

Compare **assigned-to-treatment** group to the **assigned-to-control** group.

This comparison says: effect of mammography is to reduce breast cancer mortality rate by `r round(((c1_n + nt1_n)/30) - ((c0_n + nt0_n)/30), 2)` per 1000!

---

### Mammography

Which option is the best?

Why?


---

### There are *four* possible types of people/units 

```{r, echo = F}

d = data.frame(type = c("compliers", "always takers", "never takers", "defiers"),
               when_t = c("Take", "Take", "Not Take", "Not Take"),
               when_c = c("Not Take", "Take", "Not Take", "Take")
               )

kable(d, col.names = c("Type", "Assigned to T", "Assigned to C"), format = 'html')
```

---

### Potential Outcomes

$Z$ is **assignment to treatment**; $D$ is **receipt of treatment**

```{r, echo = F}

d = data.frame(type = c("compliers", "always takers", "never takers", "defiers"),
               when_t = c(1,1,0,0),
               when_c = c(0,1,0,1)
               )

kable(d, col.names = c("Type", "$D(Z = 1)$", "$D(Z = 0)$"), format = 'html')
```

---

### Mammography:

**Option 1**: Compares 

- compliers assigned to treatment
- never-takers assigned to treatment; compliers, never-takers assigned to control

**Option 2**: Compares 

- compliers assigned to treatment
- compliers, never-takers assigned to control

Compliers and never-takers have **different potential outcomes** $\to$ bias.

---

### Mammography:

**Option 3**: Compares 

- compliers, never-takers **assigned to treatment**
- compliers, never-takers **assigned to control**

Comparison is based on **random assignment** gives us unbiased estimate.

---

When we compare and treated and untreated in a way that ignores the process of **random assignment** we run the risk of bias.

### Solution 1: Intent to Treat

One solution to non-compliance is to estimate the **intent to treat** ($ITT$) effect, as opposed to the $ACE$.

**Intent to treat** ($ITT$) compares **assigned-to-treatment** against **assigned-to-control**. Because this is randomly assigned, we know this comparison is unbiased (see Lectures 1 and 2).

--- 

### Solution 1: Intent to Treat

Where $Z$ is the treatment **assigned** and $D$ is the treatment **received**
$$ ITT = \frac{1}{N} \sum\limits_{i=1}^{N} Y_{i}(Z=1) - Y_i(Z=0)$$

$$ ITT \neq ACE = \frac{1}{N} \sum\limits_{i=1}^{N} Y_i(D=1) - Y_i(D=0)$$

unless there is perfect compliance.

--- 

### Solution 1: Intent to Treat

Why does it work?

- Treatment assignment is random; but which units actually take treatment may not be.

- $ITT$ ensures that there is **balance** in the different types of units across the comparison (e.g. in expectation same proportion compliers, never-takers) as well as their potential outcomes.

- $ITT$ is just the $ACE$, where the "cause" is **assignment to treatment**. $\widehat{ITT}$ unbiased like $\widehat{ACE}$ under same assumptions.

---
 
### Solution 1: Intent to Treat

#### Why might it be desirable?

Policy makers might care about the overall effect of policy when costs are fixed but some people don't receive it. 

- e.g. felon re-integration; reminder to apply for healthcare in US

---
 
### Solution 1: Intent to Treat

#### Might not be interesting

If...

- We  care about the **effect** of actual **exposure**
- $ITT$ usually diluted because some **never** get treated or because some people **always** get treated
- e.g., military service

--- 

### Can we do better?

# CACE

--- 

### Effects of **treatment**

If we want to find the effect of **treatment**, not just of **assignment-to-treatment**, there is a way to do better than the $ITT$.

If we add to the $ACE$ assumptions, we can find the $ACE$ for **compliers**: the **complier average causal effect** ($CACE$).

$$CACE = \frac{1}{N_c} \sum_{i = 1}^{N_c} Y_i(D = 1) - Y_i(D = 0)$$

--- 

### $CACE$

Why look at effects for **compliers**?

---

$$CACE = \frac{1}{N_c} \sum_{i = 1}^{N_c} Y_i(D = 1) - Y_i(D = 0)$$

Where $N_c$ is the number of compliers.

Suggests: maybe we just find average $Y$ for compliers in treatment; average $Y$ for compliers in control.

---

### $CACE$

How do we find compliers... in the treatment group?

```{r echo = F}
kable(hip, format = 'html',
      col.names = c("Assignment", "Screened", "$N$", "BC Deaths", "BCD per 1k", "BC Deaths (total)", "BCD per 1k (total)")) %>% 
  group_rows("Control Group", 1,1) %>% 
  group_rows("Treatment Group", 2,3)
```

---

### $CACE$

How do we find compliers... in the control group?

```{r echo = F}
kable(hip, format = 'html',
      col.names = c("Assignment", "Screened", "$N$", "BC Deaths", "BCD per 1k", "BC Deaths (total)", "BCD per 1k (total)")) %>% 
  group_rows("Control Group", 1,1) %>% 
  group_rows("Treatment Group", 2,3)
```

---

### $CACE$

Unless **everyone** is a complier, we cannot directly observe

- $Y(D = 1)$ for compliers in treatment (unless no always-takers)
- $Y(D = 0)$ for compliers in control


>- But... We don't need to directly observe compliers!

---

### $CACE$

With **three key assumptions**, can find the effect for compliers without knowing which persons are compliers!

To understand, we first need potential outcomes model.

- need an indicator for **random assignment**: $Z$
- indicator for **receipt of letter**: $D$
- what people would do, given assignment **and** treatment $Y$

--- 

Potential Outcomes of Non-Compliance:

```{r, echo = F}
d = data.frame(
               d1 = rep(c(1,1,0,0), 1), d0 = rep(c(1,0,0,1),1),
               y10 = rep(c(NA,NA,0,1), 1), y11 = rep(c(1,1,NA,NA), 1),
                y00 = rep(c(NA,0,0,NA), 1), y01 = rep(c(1,NA,NA,0), 1),
               type = rep(c("Always Taker", "Complier", "Never Taker", "Defier"), 1))

kable(d, col.names = c("$D_i(Z = 1)$", "$D_i(Z = 0)$",
                       "$Y_i(Z1,D0)$", "$Y_i(Z1,D1)$",
                        "$Y_i(Z0,D0)$", "$Y_i(Z0,D1)$", "Type"), format = 'html') %>% kable_styling(c( 'bordered', 'condensed', 'hover'))

```

---

### Assumption 1: No Defiers / Monotonicity

- Assume that "defiers" do not exist.
- We can allow for never treats *and* always treats! (why?)
- Seems plausible, but sometimes defiers may exist.

More generally:

- **assignment to treatment** $Z$ can have only positive (negative) effects on **receipt of treatment** $D$.

---

### Assumption 1: No Defiers / Monotonicity

Why do we need this assumption?

- Without defiers, the only units changing their treatment status between **assigned to control** and **assigned to treat** are **compliers**.
- With defiers, would not know the proportions of always taker/never taker/complier.

---


```{r, echo = F}
d = data.frame(
               d1 = rep(c(1,1,0), 1), d0 = rep(c(1,0,0),1),
               y10 = rep(c(NA,NA,0), 1), y11 = rep(c(1,1,NA), 1),
                y00 = rep(c(NA,0,0), 1), y01 = rep(c(1,NA,NA), 1),
               type = rep(c("Always Taker", "Complier", "Never Taker"), 1))

kable(d, col.names = c("$D_i(Z = 1)$", "$D_i(Z = 0)$",
                       "$Y_i(Z1,D0)$", "$Y_i(Z1,D1)$",
                        "$Y_i(Z0,D0)$", "$Y_i(Z0,D1)$", "Type"), format = 'html') %>% kable_styling(c( 'bordered', 'condensed', 'hover'))

```

---

### Assumption 2: Exclusion restriction

- Random assignment to treatment $Z$ **only affects outcome** ($Y$) **THROUGH treatment** ($D$). 

- If the process of assignment to treatment has its own, independent effect, we may be in trouble.

---

### Assumption 2: Exclusion restriction

Why do we need this?

- Allows us to assume that $Y(Z = 1) = Y(Z = 0)$ for **always takers** and **never takers**
- Allows us to assume that unit causal effects for **compliers** are the same in assign-to-treat and assign-to-control:
    - $Y_c(Z=0,D=0) = Y_c(Z=1, D=0)$ and $Y_c(Z=0,D=1) = Y_c(Z=1, D=1)$
    - To find effect of $D$ for compliers whose values of $D$ **and** $Z$ are different, $Z$ cannot change $Y$.

---

Always/ Never Takers

```{r, echo = F}
d = data.frame(
               d1 = rep(c(1,1,0), 1), d0 = rep(c(1,0,0),1),
               y10 = rep(c(NA,NA,0), 1), y11 = rep(c(1,1,NA), 1),
                y00 = rep(c(NA,0,0), 1), y01 = rep(c(1,NA,NA), 1),
               type = rep(c("Always Taker", "Complier", "Never Taker"), 1))

d[1, c('y11', 'y01')] = cell_spec(c(1,1), 'html', background = "green", color = 'white', bold = T)

d[3, c('y10', 'y00')] = cell_spec(c(0,0), 'html', background = "green", color = 'white', bold = T)

kable(d, col.names = c("$D_i(Z = 1)$", "$D_i(Z = 0)$",
                       "$Y_i(Z1,D0)$", "$Y_i(Z1,D1)$",
                        "$Y_i(Z0,D0)$", "$Y_i(Z0,D1)$", "Type"), format = 'html', escape = F) %>% kable_styling(c( 'bordered', 'condensed', 'hover'))
```

---

Compliers

```{r, echo = F}
d = data.frame(
               d1 = rep(c(1,1,0), 1), d0 = rep(c(1,0,0),1),
               y10 = rep(c(NA,NA,0), 1), y11 = rep(c(1,1,NA), 1),
                y00 = rep(c(NA,0,0), 1), y01 = rep(c(1,NA,NA), 1),
               type = rep(c("Always Taker", "Complier", "Never Taker"), 1))

d[2, c('y10', 'y01')] = cell_spec(c(1,0), 'html', background = "green", color = 'white', bold = T)

kable(d, col.names = c("$D_i(Z = 1)$", "$D_i(Z = 0)$",
                       "$Y_i(Z1,D0)$", "$Y_i(Z1,D1)$",
                        "$Y_i(Z0,D0)$", "$Y_i(Z0,D1)$", "Type"), format = 'html', escape = F) %>% kable_styling(c( 'bordered', 'condensed', 'hover'))

```

---

### Assumption 3: Random Assignment

Assignment to values of $Z$ is random

Assignment status of one unit does not affect treatment receipt of another. (SUTVA)

---

### Assumption 3: Random Assignment

**WHY**

- Potential outcomes of $Y$ are in expectation the same in assign-to-treat, assign-to-control $\to$ $\widehat{ITT}$ is unbiased estimator of $ITT$.

- If there is an indicator for unit type (e.g. complier, never-taker) that is in $0,1$. In expecation mean of type indicator is same assign-to-treat/assign-to-control
    - **Proportion** of compliers, never-takers, etc. **same** in both groups
    
---

### Estimating the CACE:

First, the parameter:

$$CACE = \frac{1}{N_c} \sum_{i = 1}^{N_c} Y_i(D = 1) - Y_i(D = 0)$$

$$CACE = Y_c(D = 1) - Y_c(D = 0)$$

Where $Y_c(D = 1)$ is the mean $Y(D = 1)$ for compliers

Where $Y_c(D = 0)$ is the mean $Y(D = 0)$ for compliers

---

### Estimating the CACE:

A path:

Can decompose the mean, $\bar{x}$, into the sum of $G$ sub-group means of $x$, weighted by $w$, where $w$ is the fraction of the total $N$ in subgroup $G$: $w_g = \frac{N_g}{N}$. All $w$ then sum to $1$.

$$\bar{x} = \sum\limits_{g=1}^{G} x_g \cdot w_g$$

---

### Estimating the CACE:

Within the **population** (study group):

proportion of (a)lways Takers is $\pi_{a}$
proportion of (n)ever Takers is $\pi_{n}$
proportion of (c)ompliers is $\pi_{c}$
proportion of (d)efiers is $\pi_{d}$

$\pi_{c} + \pi_{a} + \pi_{n} + \pi_{d} = 1$

Where $Y_?(1)$ indicates the mean of $Y_?(Z = 1)$ for each group. 
Where $Y_?(0)$ indicates the mean of $Y_?(Z = 0)$ for each group. 

---

### Estimating the CACE:

By this logic: 

$$ITT = Y(Z = 1) - Y(Z = 0)$$

Can be rewritten as

$$ITT = (Y_c(1)\pi_c + Y_a(1)\pi_a + Y_n(1)\pi_n + Y_d(1)\pi_d) - \\ (Y_c(0)\pi_c + Y_a(0)\pi_a + Y_n(0)\pi_n + Y_d(0)\pi_d)$$

---

### Estimating the CACE:

Assuming **no defiers**, we get:

$$ITT = (Y_c(1)\pi_c + Y_a(1)\pi_a + Y_n(1)\pi_n) - \\ (Y_c(0)\pi_c + Y_a(0)\pi_a + Y_n(0)\pi_n )$$

---

### Estimating the CACE:

Assuming the **exclusion restriction**, $Y(1) = Y(0) = Y$ for always takers and never takers.

$$ITT = (Y_c(1)\pi_c + Y_a\pi_a + Y_n\pi_n) - \\ (Y_c(0)\pi_c + Y_a\pi_a + Y_n\pi_n )$$

---

### Estimating the CACE:

Doing some subtraction, we find that only differences due to effects on compliers are left:

$$ITT = (Y_c(1)\pi_c - Y_c(0)\pi_c) + \\ (Y_a\pi_a - Y_a\pi_a)  + (Y_n\pi_n - Y_n\pi_n) $$

$$ITT = (Y_c(1)\pi_c - Y_c(0)\pi_c)$$

$$ITT = [Y_c(1) - Y_c(0)]\pi_c = CACE \cdot \pi_c$$

---

### Estimating the CACE:

Doing some rearranging, we just need to estimate two parameters to get the $CACE$:

$$\frac{ITT}{\pi_c} =  CACE $$

We need to estimate parameters $ITT$ and $\pi_c$


---

### Estimating the CACE:

We can esimate $ITT$ by assuming random assignment:

- $E(\widehat{ITT}) = ITT$

We know this from before.

---

### Estimating the CACE:

We can estimate $\pi_c$, also by random assignment.

$$ITT_D = \frac{1}{N} \sum\limits_{i=1}^{N} D_i(Z = 1) - D_i(Z = 0)$$

$$ITT_D = (1\cdot\pi_c + 1\cdot\pi_a + 0\cdot\pi_n) - \\ (0\cdot\pi_c + 1\cdot\pi_a + 0\cdot\pi_n)$$

$$ITT_D = (1\cdot\pi_c  - 0\cdot\pi_c) = \pi_c$$


---

### Estimating the CACE:

And because $ITT_D$ is also an $ITT$:

$$E(\widehat{ITT_D}) = ITT_D = \pi_c$$

---

### Estimating the CACE:

$$\widehat{CACE} = \frac{\widehat{ITT}}{\widehat{ITT_D}}$$

By dividing the estimate $\widehat{ITT}$ by the estimate of $\pi_c$, $\widehat{ITT_D}$, we can estimate the effect of treatment on **compliers**

---

### Estimating the CACE

This estimator of the $CACE$ is called the **wald estimator**

$$\widehat{CACE} = \frac{Y^T - Y^C}{D^T - D^C}$$

And it is a kind of **instrumental variables** analysis.

---

### Estimating the CACE

It turns out, the our **estimator** $\widehat{CACE}$ is **biased**:

$E \left( \frac{a}{b} \right) \neq \frac{E(a)}{E(b)}$

$CACE = E \left( \frac{ITT}{ITT_D} \right) \neq \frac{E(\widehat{ITT})}{E(\widehat{ITT_D})} = \widehat{CACE}$

but **consistent**:

as $n \to \infty$, the bias goes to $0$. Thus, this approach is biased in **small samples**

---

### Interpreting the CACE

What does this $CACE$ show us? It is the **effect of treatment** for the group of units that **changes its treatment status** due to **random assignment**; for the units that can be **randomly** induced to take treatment.

- **external validity**?: are the cases that comply with treatment assignment systematically different from the population of interest? Often, yes. CACE is limited only to compliers and may be uninformative about others.

- sometimes it is called the **local average treatment effect** or $LATE$. This emphasizes the lack of external validity by emphasizing that the effect is "local" to units that are randomly induced to take treatment.

---

Let's calculate the $\widehat{CACE}$

```{r, echo=F}
kable(hip, format = 'html',
      col.names = c("Assignment", "Screened", "$N$", "BC Deaths", "BCD per 1k", "BC Deaths (total)", "BCD per 1k (total)")) %>% 
  group_rows("Control Group", 1,1) %>% 
  group_rows("Treatment Group", 2,3)
```

---

```{r}
itt_hat = (1.83 - 1.87)
ittd_hat = (1/3) - 0

cace_hat = itt_hat/ittd_hat
cace_hat
```


# Practice


---

### Interpreting the CACE

### Remember the assumptions:

1. Random Assignment

2. Exclusion Restriction

3. Monotonicity/No defiers

